# .env
# Define the application and environment for testing
APP_ENV=test
NODE_ENV=${APP_ENV}  # Set NODE_ENV as 'test' for the testing environment

# Specify the messaging system used in the application (Kafka in this case)
MESSAGE_SYSTEM='kafka'
# MESSAGE_SYSTEM='redis'
# MESSAGE_SYSTEM='rabbitmq'

#  * crit (Critical): Serious problems with system components, but the entire system has not crashed. For example, a database connection loss or a critical component failure.
#  * error (Error): Error occurrence. Although the process can continue, logging of erroneous situations is necessary. For example, user errors or database errors.
#  * warning (Warning): There is a potential problem, but immediate intervention is not required. For example, memory usage, disk space shortage.
#  * notice (Notice): Situations that are normal in the system but that users should be aware of. New updates or release notes.
#  * info (Info): Used to follow the normal process flow in the system. A process or task that has been successfully completed.
#  * debug (Debug): Detailed logs used for development and debugging purposes. Information such as variable values ​​and method calls within the process.
APP_LOG_LEVEL=info

# Unique client ID for service
# client.<your_unique_client_id>
# If you do not define it, it will be created automatically.
# CLIENT_ID=client

# Consumer group ID for service
# group.<your_unique_group_id>
# If you do not define it, it will be created automatically.
GROUP_ID=group

# Kafka Configuration

# List of Kafka brokers to connect to
# broker1:9092,broker2:9092,broker3:9092
# local or docker internal
# kafka:19092,localhost:9092,127.0.0.1:9092
KAFKA_BROKERS=127.0.0.1:9092

# Unique client ID for Kafka
# client.<your_unique_client_id>
# If you do not define it, it will be created automatically.
# KAFKA_CLIENT_ID=${CLIENT_ID}

# Consumer group ID for Kafka
# group.<your_unique_group_id>
# If you do not define it, it will be created automatically.
KAFKA_GROUP_ID=${GROUP_ID}

# Logging level for Kafka (0: none, 1: error, 2: warn, 3: info, 4: debug, 5: trace)
KAFKA_LOG_LEVEL=0

# Timeouts for Kafka connections (milliseconds)
KAFKA_HEARTBEAT_INTERVAL=1000
KAFKA_SESSION_TIMEOUT=3000
KAFKA_CONNECTION_TIMEOUT=3000
KAFKA_AUTHENTICATION_TIMEOUT=3000
KAFKA_REQUEST_TIMEOUT=3000

# Acknowledgment setting for Kafka producer (possible values: 'all', '1', '0')
KAFKA_ACKS=all

# Number of retries for Kafka producer
KAFKA_RETRIES=10

# Initial retry time (milliseconds)
KAFKA_INITIAL_RETRY_TIME=300

# Metadata refresh interval (milliseconds)
KAFKA_METADATA_MAX_AGE=30000

# Number of partitions for Kafka topics
KAFKA_NUM_PARTITIONS=6

# Replication factor for Kafka topics
KAFKA_REPLICATION_FACTOR=3

# Auto commit setting (true or false)
KAFKA_AUTO_COMMIT=true

# Auto commit interval (milliseconds)
KAFKA_AUTO_COMMIT_INTERVAL=5000

# Minimum and maximum bytes for Kafka batch
KAFKA_MIN_BYTES=1024
KAFKA_MAX_BYTES=10485760

# Maximum wait time before sending a Kafka batch (milliseconds)
KAFKA_MAX_WAIT_TIME_IN_MS=1000

# Batch size for Kafka producer (bytes)
KAFKA_BATCH_SIZE=32768

# Linger time for Kafka producer (milliseconds)
KAFKA_LINGER_MS=100

# Key serializer for Kafka
KAFKA_KEY_SERIALIZER=org.apache.kafka.common.serialization.StringSerializer

# Value serializer for Kafka
KAFKA_VALUE_SERIALIZER=org.apache.kafka.common.serialization.StringSerializer

# MESSAGING_TOPICS
MESSAGING_TOPIC_DATA_COLLECT_REQUEST=DATA_COLLECT_REQUEST
MESSAGING_TOPIC_DATA_COLLECT_STATUS=DATA_COLLECT_STATUS
MESSAGING_TOPIC_DATA_COLLECT_RESPONSE=DATA_COLLECT_RESPONSE
MESSAGING_TOPIC_DATA_COLLECT_ERROR=DATA_COLLECT_ERROR
MESSAGING_TOPIC_JOB_SCHEDULE_CREATE=JOB_SCHEDULE_CREATE
MESSAGING_TOPIC_JOB_SCHEDULE_UPDATE=JOB_SCHEDULE_UPDATE
MESSAGING_TOPIC_JOB_STATUS=JOB_STATUS
MESSAGING_TOPIC_JOB_PROGRESS=JOB_PROGRESS
MESSAGING_TOPIC_DATA_PROCESSING_START=DATA_PROCESSING_START
MESSAGING_TOPIC_DATA_PROCESSING_STATUS=DATA_PROCESSING_STATUS
MESSAGING_TOPIC_DATA_PROCESSING_RESULT=DATA_PROCESSING_RESULT
MESSAGING_TOPIC_DATA_STORAGE=DATA_STORAGE
MESSAGING_TOPIC_DATA_AGGREGATION=DATA_AGGREGATION
MESSAGING_TOPIC_ANALYSIS_REQUEST=ANALYSIS_REQUEST
MESSAGING_TOPIC_ANALYSIS_RESULT=ANALYSIS_RESULT
MESSAGING_TOPIC_ANALYSIS_ERROR=ANALYSIS_ERROR
MESSAGING_TOPIC_ALERT=ALERT
MESSAGING_TOPIC_LOG=LOG
MESSAGING_TOPIC_NOTIFICATION=NOTIFICATION
MESSAGING_TOPIC_METRIC=METRIC
MESSAGING_TOPIC_REPORT=REPORT
MESSAGING_TOPIC_DASHBOARD=DASHBOARD

# redis
# 127.0.0.1
REDIS_HOST_ADDRESS=127.0.0.1

# 6379
REDIS_HOST_PORT=6379

# Unique client ID for Kafka
# client.<your_unique_client_id>
# If you do not define it, it will be created automatically.
# REDIS_CLIENT_ID=${CLIENT_ID}

# Consumer group ID for Kafka
# group.<your_unique_group_id>
# If you do not define it, it will be created automatically.
REDIS_GROUP_ID=${GROUP_ID}

# RabbitMQ
# 127.0.0.1
RABBITMQ_HOST_ADDRESS=127.0.0.1

# 5672
RABBITMQ_HOST_PORT=5672

# guest or admin
RABBITMQ_DEAULT_USER=guest

# guest or admin
RABBITMQ_DEFAULT_PASSWORD=guest

# Unique client ID for Kafka
# client.<your_unique_client_id>
# If you do not define it, it will be created automatically.
# RABBITMQ_CLIENT_ID=${CLIENT_ID}

# Consumer group ID for Kafka
# group.<your_unique_group_id>
# If you do not define it, it will be created automatically.
RABBITMQ_GROUP_ID=${GROUP_ID}

# Telemetrys
# Zipkin Configuration
ZIPKIN_HOST_ADDRESS=localhost
ZIPKIN_HOST_PORT=9411

# Jaeger Configuration
JAEGER_HOST_ADDRESS=localhost
JAEGER_OTLP_GRPC_PORT=4317    # OTLP gRPC
JAEGER_OTLP_HTTP_PORT=4318    # OTLP HTTP
JAEGER_AGENT_PORT=5778
JAEGER_ZIPKIN_PORT=9412       # Jaeger Zipkin compatable
JAEGER_HOST_PORT=14250        # Jaeger gRPC port (collector)
JAEGER_HTTP_PORT=14268        # Jaeger HTTP (traces)
JAEGER_UI_PORT=16686          # Jaeger UI

# Open Telemetry Collector
OTLP_HOST_ADDRESS=127.0.0.1
OTLP_HOST_PORT=4317

# logstash
LOGTASH_HOST_ADDRESS=127.0.0.1
LOGTASH_HOST_PORT=5044

# graylog
GRAYLOG_HOST_ADDRESS=127.0.0.1
GRAYLOG_HOST_PORT=12201